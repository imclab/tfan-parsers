# -*- coding: utf-8 -*-

from Errors import FormatError
import re
import numpy

class StaibDat(dict):
  """
  Imports XPS and AES data from Staib .dat file and provides useful features.

  The StaibDat class imports data from a Staib AES or XPS .dat file created by 
  the winspectro software, and makes this data available like a python 
  dictionary. The class tests the data file and the data itself before it 
  returns an object. See the README file for more information about the 
  assumptions made regarding the structure of these files. Since there is no 
  published standard of the structure of the Staib .dat file format, the 
  parsing done by this class will be as general as possible.
  
  There are several ways to access data in a StaibDat object. Since the 
  winspectro .dat files resemble the key-value pairs of a dictionary, the user
  can directly access the data pulled in from the file simply via the key in 
  the data file. The StaibDat class fixes any keys in the .dat file so that 
  there are no spaces or characteris that aren't text, numbers or dashes.
  
  In addition to keys explicit in the .dat file, the StaibDat class provides the
  following data and methods for the convenience of the user (units in 
  brackets):
    filename: The name of the file from which the data in the object came.
    fileText: A list with the full text of the data file. Each list item 
      contains a single line of the file.
    KE [eV]: A numpy array containing the kinetic energy value of the electrons.
    BE [eV]: A numpy array containing the binding energy of the electrons 
      calculated using the value of the source energy. Note that this array will
      still be calculated for AES data, but will equal KE since the source 
      energy is zero.
    C1 [count]: A numpy array containing the number of counts for a particular
      energy for channel 1.
    C2 [count]: A numpy array containing the number of counts for a particular
      energy for channel 2.
    smooth: Method that returns a numpy array of smoothed data.
    differentiate: Method that returns numpy array of first derivative of data.
      
  Generally, the user will probably find it easier to work with the KE, BE, etc.
  data as opposed to the dictionary data pulled from the file itself.
  """

  def __init__(self,filename):
    """
    Instantiation of StaibDat object.

    A StaibDat object is instantiated with a string referring to a .dat file 
    containing AES or XPS data generated by winspectro.
    """

    # The StaibDat object should know where its data came from.
    self["filename"] = filename
    
    # Pull in the data from the file and close the file.
    datFile = open(filename,"r")
    self["fileText"] = datFile.readlines()
    datFile.close()
    
    # Verify the data file has the correct structure.
    self.verifystructure()
    
    # Step through the lines and match them.
    for line in self["fileText"]:
      self.parseline(line)
      
    # Verify that the metadata and data in the file agree.
    self.verifydata()
      
    # Generate the user-friendly KE, C1, etc. numpy arrays.
    self.userfriendify()
    
  def verifystructure(self):
    """
    Verify that the imported text data has the proper structure.
    """
    
    lineTypeList = []
    
    for line in self["fileText"]:
      lineTypeList.append(self.verifyline(line))

    if "other" in lineTypeList:
      raise FormatError
    elif lineTypeList.count("datalabels") != 1:
      raise FormatError
    
    compressedList = []
    
    for lineType in lineTypeList:
      if len(compressedList) == 0:
        compressedList.append(lineType)
      elif lineType != compressedList[-1]:
        compressedList.append(lineType)
        
    if compressedList != ["metadata","reserved","datalabels","data"]:
      raise FormatError

  def verifyline(self,line):
    """
    Returns a string indicating what section of the file the line comes from.
    """
    datRE = re.compile("\s+(\d+)\s+(\d+)\s+(\-*\d+)")
    datLabelsRE = re.compile("\s+(Basis\[mV\])\s+(Channel_1)\s+(Channel_2)")
    
    if re.search(r":    ",line):
      return "metadata"
    elif line.strip() == "reserved":
      return "reserved"
    elif datLabelsRE.search(line):      
      return "datalabels"
    elif datRE.search(line):      
      return "data"
    else:
      return "other"
      
  def verifydata(self):
    """
    Compares the values in the metadata section to those in the data section.
    """
    
    # Data Points should equal the number of data points.
    if self["DataPoints"] != len(self["Basis"]["value"]):
      raise FormatError
    
    # The last value of energy should equal Stopenergy.
    if round(self["Stopenergy"]["value"],2) != round(self["Basis"]["value"][-1]/1000,2):
      raise FormatError
       
    # The first value of energy should equal Startenergy.
    if round(self["Startenergy"]["value"],2) != round(self["Basis"]["value"][0]/1000,2):
      raise FormatError
    
    # The difference between each Basis value should be consistent.
    basisList = self["Basis"]["value"][:]
    
    diffList = []
    val = basisList.pop()
    while len(basisList):
      bottomVal = basisList.pop()
      diffList.append(round((val-bottomVal)/1000,2))
      val = bottomVal
      
    if diffList.count(diffList[0]) != len(diffList):
      raise FormatError
    
    # The difference between each Basis value should equal Stepwidth.
    if diffList[0] != round(self["Stepwidth"]["value"],2):
      raise FormatError
       
  def parseline(self,line):
    """
    Determine if line is metadata, reserved, data, or other. Act accordingly.
    """

    # Set up the regular expression necessary to handle the data section of the
    # file.
    # !!!Note: the following re isn't as general as it could be. I could 
    # search for one or more instances of whitespace and not-whitespace.
    datRE = re.compile("\s+(Basis\[mV\]|\d+)" +\
                       "\s+(Channel_1|\d+)" +\
                       "\s+(Channel_2|\-*\d+)")
   
    # metadata
    if re.search(r":    ",line):
      self.metadata(line)

    # reserved
    elif line.strip() == "reserved":
      # Do nothing.
      pass

    # data
    elif datRE.search(line):      
      self.data(line,datRE)
     
  def metadata(self,line):
    """
    Set the metadata as key:value pairs in the StaibDat object.

    In the metadata part of the file, metadata keys and values are separated
    by a colon followed by four whitespace characters. The metadata method 
    splits the line up along that delimiter, prepares the key part of the text
    so that it is a legitimate key string, and then sets the key:value pairs
    in the StaibDat object.

    Some metadata has either implicit or explicit units. The metadata method
    includes these units as part of the value of the key:value pair.
    """

    # Split the key and value and remove/compress the whitespace from the key.
    [key,value] = line.split(":    ")
    # Strip, compress whitespace out of key string.
    key = re.sub("\s+","",key)
    # Strip preceeding and trailing whitespace.
    value = value.strip()

    # Deal with keys that have explicit units.
    if key[-1] == "]":
      # Break off the explicit unit.
      unit = key[-2]
      key = key[0:-3]
      self[key] = {"value":float(value),"unit":unit}
        
    # Deal with keys that have implicit units.
    elif key == "SourceEnergy":
      self[key] = {"value":float(value),"unit":"V"}
    elif key == "Stepwidth":
      self[key] = {"value":float(value),"unit":"V"}
    elif key == "DwellTime":
      self[key] = {"value":float(value),"unit":"ms"}
    elif key == "RetraceTime":
      self[key] = {"value":float(value),"unit":"ms"}

    # Deal with keys that have no units. Coerce the value to int if possible.
    else:
      try:
        value = int(value)
      except ValueError:
        pass
      self[key] = value
   
  def data(self,line,datRE):
    """
    Set the data in the StaibDat object.

    In the data part of the file, the data is arranged in whitespace-separated
    columns. The first line of the data is the labels for the columns, and each
    subsequent line contains the actual data. In the resulting StaibDat object,
    each column of data will have its own key:value pair; the key being the 
    formatted column label, and the value being another dictionary. The value
    dictionary has two keys: unit and value. The unit element is a string 
    containing the unit of the data. The value element is an array containing 
    the values in the column.
    """

    parsedData = datRE.match(line)
    
    if parsedData.group(1) == "Basis[mV]":
      self["Basis"] = {"value":[],"unit":"V"}
      self["Channel_1"] = {"value":[],"unit":"count"}
      self["Channel_2"] = {"value":[],"unit":"count"}
    else:
      self["Basis"]["value"].append(float(parsedData.group(1)))
      self["Channel_1"]["value"].append(float(parsedData.group(2)))
      self["Channel_2"]["value"].append(float(parsedData.group(3)))

  def userfriendify(self):
    """
    Generate the numpy arrays for KE, BE (if available), C1, and C2.
    
    According to conversations with Staib, the analyzer has an internal bias
    and therefore we don't have to compensate for the analyzer work function.
    """
    
    self["KE"] = numpy.array(self["Basis"]["value"])/1000
    self["BE"] = self["KE"] - self["SourceEnergy"]["value"]
    self["C1"] = numpy.array(self["Channel_1"]["value"])
    self["C2"] = numpy.array(self["Channel_2"]["value"])
  
  def smooth(self, key, kernel = 13, order = 3):
    """
    Returns numpy array of smoothed data.
    
    This method uses Savitzky-Golay to smooth the data given in one of the 
    StaibDat class's default data arrays. Input arguments as well as their 
    default values are given as follows:
      key: A string indicating which of the object's data should be smoothed 
        (e.g. C1, C2).
      kernel: A positive integer giving the number of points the smoothing 
        algorithm should consider. Default = 13.
      order: A positive integer giving the order of the polynomial used in the 
        smoothing algorithm. Default = 3.
        
    The implementation of Savitzky-Golay was wholesale copied and slightly 
    modified from the SciPy cookbook: 
      http://www.scipy.org/Cookbook/SavitzkyGolay

    See the original Savitzky-Golay paper at DOI: 10.1021/ac60214a047
    """

    return self.savitzky_golay(self[key],kernel,order,deriv = 0)
  
  def differentiate(self, key, kernel = 13, order= 3):
    """
    Returns numpy array of approximation of first derivative of data.
    
    This method uses Savitzky-Golay to approximate the first derivative of the 
    data given in one of the StaibDat class's default data arrays. Input 
    arguments as well as their default values are given as follows:
      key: A string indicating which of the object's data should be smoothed 
        (e.g. C1, C2).
      kernel: A positive integer giving the number of points the smoothing 
        algorithm should consider. Default = 13.
      order: A positive integer giving the order of the polynomial used in the 
        smoothing algorithm. Default = 3.
        
    The implementation of Savitzky-Golay was wholesale copied and slightly 
    modified from the SciPy cookbook: 
      http://www.scipy.org/Cookbook/SavitzkyGolay

    See the original Savitzky-Golay paper at DOI: 10.1021/ac60214a047
    """

    return self.savitzky_golay(self[key],kernel,order,deriv = 1)

  def savitzky_golay(self, data, kernel, order, deriv):
    """
    Return smooth or differentiated data according to the Savitzky-Golay 
    algorithm.
    
    The implementation of Savitzky-Golay was wholesale copied and slightly 
    modified from the SciPy cookbook: 
      http://www.scipy.org/Cookbook/SavitzkyGolay

    See the original Savitzky-Golay paper at DOI: 10.1021/ac60214a047
    """
    try:
      kernel = abs(int(kernel))
      order = abs(int(order))
    except ValueError, msg:
      raise ValueError("kernel and order have to be of type int (floats will be converted).")
    if kernel % 2 != 1 or kernel < 1:
      raise TypeError("kernel size must be a positive odd number, was: %d" % kernel)
    if kernel < order + 2:
      raise TypeError("kernel is to small for the polynomals\nshould be > order + 2")

    # a second order polynomal has 3 coefficients
    order_range = range(order+1)
    half_window = (kernel -1) // 2
    b = numpy.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])
    # since we don't want the derivative, else choose [1] or [2], respectively
    m = numpy.linalg.pinv(b).A[deriv]
    window_size = len(m)
    half_window = (window_size-1) // 2

    # precompute the offset values for better performance
    offsets = range(-half_window, half_window+1)
    offset_data = zip(offsets, m)

    smooth_data = list()

    # temporary data, with padded zeros (since we want the same length after smoothing)
    data = numpy.concatenate((numpy.zeros(half_window), data, numpy.zeros(half_window)))
    for i in range(half_window, len(data) - half_window):
      value = 0.0
      for offset, weight in offset_data:
        value += weight * data[i + offset]
      smooth_data.append(value)
    return numpy.array(smooth_data)
